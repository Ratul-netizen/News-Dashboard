
import {
    tokenizeBanglaText,
    calculateSemanticSimilarity,
    calculateContextAwareSemanticSimilarity,
    calculateAdvancedSemanticSimilarity
} from '../lib/utils/semantic-similarity';

// Need to access the module internals or duplicate logic to test specifics like stop words if they aren't exported.
// Since tokenizeBanglaText is exported (implied by usage, though checking file showed it wasn't, I will assume I need to export or check logic indirectly via tokenization)
// Actually tokenizeBanglaText was NOT exported in the original file view, only calculate* functions were.
// I will check the file again to see if I need to export it or just test via similarity results. 
// For this script, I will try to use the exported functions effectively.

console.log("ðŸ§ª Verifying Bengali Semantic Similarity Refinements...\n");

// Mock function to expose tokenization if not exported 
// (or I relied on previous knowledge/edits - let's verify stop words via similarity)
// If "à¦¢à¦¾à¦•à¦¾" is a stop word, "à¦¢à¦¾à¦•à¦¾" vs "à¦¢à¦¾à¦•à¦¾" might be 0 or handled as empty? 
// No, invalid input handling returns 0. 

// Actually, tokenizeBanglaText is LOCAL in the file, not exported. 
// However, I can infer behavior from `batchSemanticSimilarity` or just running similarity on simple strings.

function test() {
    // Test 1: Stop Word Cleanup
    // "à¦¢à¦¾à¦•à¦¾" and "à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶" should NOT be removed. 
    // If they were removed, similarity of "à¦¢à¦¾à¦•à¦¾" vs "à¦¢à¦¾à¦•à¦¾" would be 0 (empty tokens).
    // If kept, similarity should be 1.0.
    const loc1 = "à¦¢à¦¾à¦•à¦¾";
    const loc2 = "à¦¢à¦¾à¦•à¦¾";
    const simLoc = calculateSemanticSimilarity(loc1, loc2);
    console.log(`Test 1a: Entity Retention (Dhaka) -> Similarity: ${simLoc}`);
    if (simLoc > 0.9) console.log("âœ… PASS: 'Dhaka' is preserved.");
    else console.log("âŒ FAIL: 'Dhaka' was removed!");

    // "à¦à¦¬à¦‚" should be removed.
    // "à¦à¦¬à¦‚" vs "à¦à¦¬à¦‚" -> if removed, both empty -> returns 0.
    const stop1 = "à¦à¦¬à¦‚";
    const stop2 = "à¦à¦¬à¦‚";
    const simStop = calculateSemanticSimilarity(stop1, stop2);
    console.log(`Test 1b: Stop Word Removal (Ebong) -> Similarity: ${simStop}`);
    if (simStop === 0) console.log("âœ… PASS: 'Ebong' is removed.");
    else console.log("âŒ FAIL: 'Ebong' was kept!");

    // Test 2: Normalization Safety
    // "à¦…à¦ªà¦°à¦¾à¦§" should NOT become "à¦ªà¦°à¦¾à¦§" (prefix 'à¦…' stripping).
    // "à¦…à¦ªà¦°à¦¾à¦§" vs "à¦ªà¦°à¦¾à¦§" should represent whether they normalized to same thing.
    // But better test: "à¦…à¦ªà¦°à¦¾à¦§" vs "à¦…à¦ªà¦°à¦¾à¦§" should be 1.0.
    // And "à¦…à¦ªà¦°à¦¾à¦§" vs "à¦ªà¦°à¦¾à¦§" should ideally be LOWER if normalization is safe (they are different words).
    const w1 = "à¦…à¦ªà¦°à¦¾à¦§";
    const w2 = "à¦ªà¦°à¦¾à¦§";
    // If aggressive stripping: both -> "à¦ªà¦°à¦¾à¦§" -> sim 1.0
    // If safe stripping: "à¦…à¦ªà¦°à¦¾à¦§" keeps "à¦…à¦ªà¦°à¦¾à¦§", "à¦ªà¦°à¦¾à¦§" keeps "à¦ªà¦°à¦¾à¦§" -> sim 0
    const simNorm = calculateSemanticSimilarity(w1, w2);
    console.log(`Test 2a: Normalization Safety (Oporadh vs Poradh) -> Similarity: ${simNorm}`);
    if (simNorm < 0.99) console.log("âœ… PASS: aggressive 'O' stripping prevented.");
    else console.log("âŒ FAIL: 'Oporadh' stripped to 'Poradh'!");

    // Suffix: "à¦›à§‡à¦²à§‡à¦¦à§‡à¦°" -> "à¦›à§‡à¦²à§‡" (suffix 'à¦¦à§‡à¦°' removal).
    // "à¦›à§‡à¦²à§‡" vs "à¦›à§‡à¦²à§‡à¦¦à§‡à¦°" -> should be 1.0.
    const s1 = "à¦›à§‡à¦²à§‡";
    const s2 = "à¦›à§‡à¦²à§‡à¦¦à§‡à¦°";

    const simSuffix = calculateSemanticSimilarity(s1, s2);
    console.log(`Test 2b: Suffix Normalization (Chele vs Cheleder) -> Similarity: ${simSuffix}`);
    if (simSuffix > 0.9) console.log("âœ… PASS: Suffix 'der' normalized correctly.");
    else console.log("âŒ FAIL: Suffix likely not handled or over-stripped.");

    // Test 3: Entity Extraction (Suffix Patterns)
    // "à¦°à¦¹à¦¿à¦® à¦‰à¦¦à§à¦¦à¦¿à¦¨" should match "à¦°à¦¹à¦¿à¦® à¦‰à¦¦à§à¦¦à¦¿à¦¨" with high boost.
    const name1 = "à¦¸à¦¨à§à¦¤à§à¦°à¦¾à¦¸à§€ à¦°à¦¹à¦¿à¦® à¦‰à¦¦à§à¦¦à¦¿à¦¨ à¦§à¦°à¦¾ à¦ªà§œà§‡à¦›à§‡";
    const name2 = "à¦°à¦¹à¦¿à¦® à¦‰à¦¦à§à¦¦à¦¿à¦¨ à¦—à§à¦°à§‡à¦«à¦¤à¦¾à¦°";
    const simContext = calculateContextAwareSemanticSimilarity(name1, name2);
    console.log(`Test 3: Entity Context Boost (Rahim Uddin) -> Similarity: ${simContext.toFixed(3)}`);

    // Compare with non-entity similarity to ensure boost works
    // "à¦¸à¦¨à§à¦¤à§à¦°à¦¾à¦¸à§€ à¦§à¦°à¦¾ à¦ªà§œà§‡à¦›à§‡" vs "à¦—à§à¦°à§‡à¦«à¦¤à¦¾à¦°" (low overlap)
    const base1 = "à¦¸à¦¨à§à¦¤à§à¦°à¦¾à¦¸à§€ à¦§à¦°à¦¾ à¦ªà§œà§‡à¦›à§‡";
    const base2 = "à¦—à§à¦°à§‡à¦«à¦¤à¦¾à¦°";
    const simBase = calculateSemanticSimilarity(base1, base2);
    console.log(`(Baseline for comparison: ${simBase.toFixed(3)})`);

    if (simContext > simBase) console.log("âœ… PASS: Entity boost active for name pattern.");
    else console.log("âŒ FAIL: No boost detected for name pattern.");

    // Test 4: IDF Stability (Simple check)
    // Just ensuring it doesn't crash or return NaN on weird inputs.
    const idfCheck = calculateSemanticSimilarity("test", "test");
    console.log(`Test 4: basic sanity -> ${idfCheck}`);
    if (!isNaN(idfCheck)) console.log("âœ… PASS: Calculation stable.");
}

test();
